{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving classification problems with CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/catboost/tutorials/blob/master/classification/classification_tutorial.ipynb)\n",
    "\n",
    "In this tutorial we will use dataset Amazon Employee Access Challenge from [Kaggle](https://www.kaggle.com) competition for our experiments. Data can be downloaded [here](https://www.kaggle.com/c/amazon-employee-access-challenge/data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user --upgrade catboost\n",
    "#!pip install --user --upgrade ipywidgets\n",
    "#!pip install shap\n",
    "#!pip install sklearn\n",
    "#!pip install --upgrade numpy\n",
    "#!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "print(catboost.__version__)\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "import catboost\n",
    "from catboost import *\n",
    "from catboost import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r\"train_s3TEQDk.csv\")\n",
    "test_df  = pd.read_csv(r\"test_mSzZ8RL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df.drop('ID',1)\n",
    "test_df=test_df.drop('ID',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(train_df, test_df) = catboost.datasets.amazon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label values extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df.Is_Lead\n",
    "X = train_df.drop('Is_Lead', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical features declaration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cat_features = list(range(0, X.shape[1]))\n",
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [0, 2, 3, 4, 6, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking on label balance in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Labels: {}'.format(set(y)))\n",
    "print('Zero count = {}, One count = {}'.format(len(y) - sum(y), sum(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ways to create Pool class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset_dir = './amazon'\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.makedirs(dataset_dir)\n",
    "\n",
    "# We will be able to work with files with/without header and\n",
    "# with different separators.\n",
    "train_df.to_csv(\n",
    "    os.path.join(dataset_dir, 'train.tsv'),\n",
    "    index=False, sep='\\t', header=False\n",
    ")\n",
    "test_df.to_csv(\n",
    "    os.path.join(dataset_dir, 'test.tsv'),\n",
    "    index=False, sep='\\t', header=False\n",
    ")\n",
    "\n",
    "train_df.to_csv(\n",
    "    os.path.join(dataset_dir, 'train.csv'),\n",
    "    index=False, sep=',', header=True\n",
    ")\n",
    "test_df.to_csv(\n",
    "    os.path.join(dataset_dir, 'test.csv'),\n",
    "    index=False, sep=',', header=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!head amazon/train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from catboost.utils import create_cd\n",
    "feature_names = dict()\n",
    "for column, name in enumerate(train_df):\n",
    "    if column == 0:\n",
    "        continue\n",
    "    feature_names[column - 1] = name\n",
    "    \n",
    "create_cd(\n",
    "    label=0, \n",
    "    cat_features=list(range(1, train_df.columns.shape[0])),\n",
    "    feature_names=feature_names,\n",
    "    output_path=os.path.join(dataset_dir, 'train.cd')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!cat amazon/train.cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pool1 = Pool(data=X, label=y, cat_features=cat_features)\n",
    "pool2 = Pool(\n",
    "    data=os.path.join(dataset_dir, 'train.csv'), \n",
    "    delimiter=',', \n",
    "    column_description=os.path.join(dataset_dir, 'train.cd'),\n",
    "    has_header=True\n",
    ")\n",
    "pool3 = Pool(data=X, cat_features=cat_features)\n",
    "\n",
    "# Fastest way to create a Pool is to create it from numpy matrix.\n",
    "# This way should be used if you want fast predictions\n",
    "# or fastest way to load the data in python.\n",
    "\n",
    "X_prepared = X.values.astype(str).astype(object)\n",
    "# For FeaturesData class categorial features must have type str\n",
    "\n",
    "pool4 = Pool(\n",
    "    data=FeaturesData(\n",
    "        cat_feature_data=X_prepared,\n",
    "        cat_feature_names=list(X)\n",
    "    ),\n",
    "    label=y.values\n",
    ")\n",
    "\n",
    "print('Dataset shape')\n",
    "print('dataset 1:' + str(pool1.shape) +\n",
    "      '\\ndataset 2:' + str(pool2.shape) + \n",
    "      '\\ndataset 3:' + str(pool3.shape) +\n",
    "      '\\ndataset 4: ' + str(pool4.shape))\n",
    "\n",
    "print('\\n')\n",
    "print('Column names')\n",
    "print('dataset 1:')\n",
    "print(pool1.get_feature_names()) \n",
    "print('\\ndataset 2:')\n",
    "print(pool2.get_feature_names())\n",
    "print('\\ndataset 3:')\n",
    "print(pool3.get_feature_names())\n",
    "print('\\ndataset 4:')\n",
    "print(pool4.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.fillna('nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=test_df.fillna('nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split your data into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=0.8, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible options for binary classification:\n",
    "\n",
    "`Logloss`\n",
    "\n",
    "`CrossEntropy` for probabilities in target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=5,\n",
    "    learning_rate=0.1,\n",
    "    # loss_function='CrossEntropy'\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    verbose=False\n",
    ")\n",
    "print('Model is fitted: ' + str(model.is_fitted()))\n",
    "print('Model params:')\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stdout of the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "#     verbose=5,\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics calculation and graph plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=50,\n",
    "    random_seed=63,\n",
    "    learning_rate=0.5,\n",
    "    custom_loss=['AUC', 'Accuracy']\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    verbose=False,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = CatBoostClassifier(\n",
    "    learning_rate=0.7,\n",
    "    iterations=100,\n",
    "    random_seed=0,\n",
    "    train_dir='learing_rate_0.7'\n",
    ")\n",
    "\n",
    "model2 = CatBoostClassifier(\n",
    "    learning_rate=0.01,\n",
    "    iterations=100,\n",
    "    random_seed=0,\n",
    "    train_dir='learing_rate_0.01'\n",
    ")\n",
    "model1.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    cat_features=cat_features,\n",
    "    verbose=False\n",
    ")\n",
    "model2.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    cat_features=cat_features,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import MetricVisualizer\n",
    "MetricVisualizer(['learing_rate_0.01', 'learing_rate_0.7']).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    random_seed=63,\n",
    "    learning_rate=0.5,\n",
    "#     use_best_model=False\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    verbose=False,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tree count: ' + str(model.tree_count_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import cv\n",
    "\n",
    "params = {}\n",
    "params['loss_function'] = 'Logloss'\n",
    "params['iterations'] = 80\n",
    "params['custom_loss'] = 'AUC'\n",
    "params['random_seed'] = 63\n",
    "params['learning_rate'] = 0.5\n",
    "\n",
    "cv_data = cv(\n",
    "    params = params,\n",
    "    pool = Pool(X, label=y, cat_features=cat_features),\n",
    "    fold_count=5,\n",
    "    shuffle=True,\n",
    "    partition_random_seed=0,\n",
    "    plot=True,\n",
    "    stratified=False,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_value = np.min(cv_data['test-Logloss-mean'])\n",
    "best_iter = np.argmin(cv_data['test-Logloss-mean'])\n",
    "\n",
    "print('Best validation Logloss score, not stratified: {:.4f}±{:.4f} on step {}'.format(\n",
    "    best_value,\n",
    "    cv_data['test-Logloss-std'][best_iter],\n",
    "    best_iter)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data = cv(\n",
    "    params = params,\n",
    "    pool = Pool(X, label=y, cat_features=cat_features),\n",
    "    fold_count=5,\n",
    "    type = 'Classical',\n",
    "    shuffle=True,\n",
    "    partition_random_seed=0,\n",
    "    plot=True,\n",
    "    stratified=True,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "best_value = np.min(cv_data['test-Logloss-mean'])\n",
    "best_iter = np.argmin(cv_data['test-Logloss-mean'])\n",
    "\n",
    "print('Best validation Logloss score, stratified: {:.4f}±{:.4f} on step {}'.format(\n",
    "    best_value,\n",
    "    cv_data['test-Logloss-std'][best_iter],\n",
    "    best_iter)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_early_stop = CatBoostClassifier(\n",
    "    iterations=200,\n",
    "    random_seed=63,\n",
    "    learning_rate=0.5,\n",
    "    early_stopping_rounds=20\n",
    ")\n",
    "model_with_early_stop.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    verbose=False,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_with_early_stop.tree_count_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_early_stop = CatBoostClassifier(\n",
    "    eval_metric='AUC',\n",
    "    iterations=200,\n",
    "    random_seed=63,\n",
    "    learning_rate=0.5,\n",
    "    early_stopping_rounds=20\n",
    ")\n",
    "model_with_early_stop.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    verbose=False,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_with_early_stop.tree_count_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    random_seed=63,\n",
    "    iterations=500,\n",
    "    learning_rate=0.03,\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    verbose=False,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://habrastorage.org/webt/y4/1q/yq/y41qyqfm9mcerp2ziys48phpjia.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.utils import get_roc_curve\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "eval_pool = Pool(X_validation, y_validation, cat_features=cat_features)\n",
    "curve = get_roc_curve(model, eval_pool)\n",
    "(fpr, tpr, thresholds) = curve\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "lw = 2\n",
    "\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc, alpha=0.5)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('Receiver operating characteristic', fontsize=20)\n",
    "plt.legend(loc=\"lower right\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.utils import get_fpr_curve\n",
    "from catboost.utils import get_fnr_curve\n",
    "\n",
    "(thresholds, fpr) = get_fpr_curve(curve=curve)\n",
    "(thresholds, fnr) = get_fnr_curve(curve=curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "lw = 2\n",
    "\n",
    "plt.plot(thresholds, fpr, color='blue', lw=lw, label='FPR', alpha=0.5)\n",
    "plt.plot(thresholds, fnr, color='green', lw=lw, label='FNR', alpha=0.5)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Threshold', fontsize=16)\n",
    "plt.ylabel('Error Rate', fontsize=16)\n",
    "plt.title('FPR-FNR curves', fontsize=20)\n",
    "plt.legend(loc=\"lower left\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.utils import select_threshold\n",
    "\n",
    "print(select_threshold(model=model, data=eval_pool, FNR=0.01))\n",
    "print(select_threshold(model=model, data=eval_pool, FPR=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snapshotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !rm 'catboost_info/snapshot.bkp'\n",
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    save_snapshot=True,\n",
    "    snapshot_file='snapshot.bkp',\n",
    "    snapshot_interval=1,\n",
    "    random_seed=43\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    cat_features=cat_features,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict_proba(data=X_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(data=X_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pred = model.predict(\n",
    "    data=X_validation,\n",
    "    prediction_type='RawFormulaVal'\n",
    ")\n",
    "print(raw_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import exp\n",
    "\n",
    "sigmoid = lambda x: 1 / (1 + exp(-x))\n",
    "\n",
    "probabilities = sigmoid(raw_pred)\n",
    "\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prepared = X_validation.values.astype(str).astype(object)\n",
    "# For FeaturesData class categorial features must have type str\n",
    "\n",
    "fast_predictions = model.predict_proba(\n",
    "    data=FeaturesData(\n",
    "        cat_feature_data=X_prepared,\n",
    "        cat_feature_names=list(X_validation)\n",
    "    )\n",
    ")\n",
    "print(fast_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Staged prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_gen = model.staged_predict_proba(\n",
    "    data=X_validation,\n",
    "    ntree_start=0, \n",
    "    ntree_end=5, \n",
    "    eval_period=1\n",
    ")\n",
    "try:\n",
    "    for iteration, predictions in enumerate(predictions_gen):\n",
    "        print('Iteration ' + str(iteration) + ', predictions:')\n",
    "        print(predictions)\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving MultiClassification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=50,\n",
    "    random_seed=43,\n",
    "    loss_function='MultiClass'\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    verbose=False,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multiclass problems with many classes sometimes it's better to solve classification problem using ranking.\n",
    "To do that we will build a dataset with groups.\n",
    "Every group will represent one object from our initial dataset.\n",
    "But it will have one additional categorical feature - possible class value.\n",
    "Target values will be equal to 1 if the class value is equal to the correct class, and 0 otherwise.\n",
    "Thus each group will have exactly one 1 in labels, and some zeros.\n",
    "You can put all possible class values in the group or you can try setting only hard negatives if there are too many labels.\n",
    "We'll show this approach on an example of binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def build_multiclass_ranking_dataset(X, y, cat_features, label_values=[0,1], start_group_id=0):\n",
    "    ranking_matrix = []\n",
    "    ranking_labels = []\n",
    "    group_ids = []\n",
    "\n",
    "    X_train_matrix = X.values\n",
    "    y_train_vector = y.values\n",
    "\n",
    "    for obj_idx in range(X.shape[0]):\n",
    "        obj = list(X_train_matrix[obj_idx])\n",
    "\n",
    "        for label in label_values:\n",
    "            obj_of_given_class = deepcopy(obj)\n",
    "            obj_of_given_class.append(label)\n",
    "            ranking_matrix.append(obj_of_given_class)\n",
    "            ranking_labels.append(float(y_train_vector[obj_idx] == label)) \n",
    "            group_ids.append(start_group_id + obj_idx)\n",
    "        \n",
    "    final_cat_features = deepcopy(cat_features)\n",
    "    final_cat_features.append(X.shape[1]) # new feature that we are adding should be categorical.\n",
    "    return Pool(ranking_matrix, ranking_labels, cat_features=final_cat_features, group_id = group_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoost\n",
    "params = {'iterations':150, 'learning_rate':0.01, 'l2_leaf_reg':30, 'random_seed':0, 'loss_function':'QuerySoftMax'}\n",
    "\n",
    "groupwise_train_pool = build_multiclass_ranking_dataset(X_train, y_train, cat_features, [0,1])\n",
    "groupwise_eval_pool = build_multiclass_ranking_dataset(X_validation, y_validation, cat_features, [0,1], X_train.shape[0])\n",
    "\n",
    "model = CatBoost(params)\n",
    "model.fit(\n",
    "    X=groupwise_train_pool,\n",
    "    verbose=False,\n",
    "    eval_set=groupwise_eval_pool,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing predictions with ranking mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "obj = list(X_validation.values[0])\n",
    "ratings = []\n",
    "for label in [0,1]:\n",
    "    obj_with_label = deepcopy(obj)\n",
    "    obj_with_label.append(label)\n",
    "    rating = model.predict([obj_with_label])[0]\n",
    "    ratings.append(rating)\n",
    "print('Raw values:', np.array(ratings))\n",
    "\n",
    "def soft_max(values):\n",
    "    return [math.exp(val) / sum([math.exp(val) for val in values]) for val in values]\n",
    "\n",
    "print('Probabilities', np.array(soft_max(ratings)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric evaluation on a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    random_seed=63,\n",
    "    iterations=200,\n",
    "    learning_rate=0.03,\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    verbose=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.eval_metrics(\n",
    "    data=pool1,\n",
    "    metrics=['Logloss','AUC'],\n",
    "    ntree_start=0,\n",
    "    ntree_end=0,\n",
    "    eval_period=1,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AUC values:')\n",
    "print(np.array(metrics['AUC']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = model.get_feature_importance(pool1, type='ShapValues')\n",
    "expected_value = shap_values[0,-1]\n",
    "shap_values = shap_values[:,:-1]\n",
    "print(shap_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(expected_value, shap_values[3,:], X.iloc[3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(expected_value, shap_values[91,:], X.iloc[91,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_small = X.iloc[0:200]\n",
    "shap_small = shap_values[:200]\n",
    "shap.force_plot(expected_value, shap_small, X_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from catboost.eval.catboost_evaluation import *\n",
    "learn_params = {'iterations': 20, # 2000\n",
    "                'learning_rate': 0.5, # we set big learning_rate,\n",
    "                                      # because we have small\n",
    "                                      # #iterations\n",
    "                'random_seed': 0,\n",
    "                'verbose': False,\n",
    "                'loss_function' : 'Logloss',\n",
    "                'boosting_type': 'Plain'}\n",
    "evaluator = CatboostEvaluation('amazon/train.tsv',\n",
    "                               fold_size=10000, # <= 50% of dataset\n",
    "                               fold_count=20,\n",
    "                               column_description='amazon/train.cd',\n",
    "                               partition_random_seed=0,\n",
    "                               #working_dir=... \n",
    ")\n",
    "result = evaluator.eval_features(learn_config=learn_params,\n",
    "                                 eval_metrics=['Logloss', 'Accuracy'],\n",
    "                                 features_to_eval=[6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.eval.evaluation_result import *\n",
    "logloss_result = result.get_metric_results('Logloss')\n",
    "logloss_result.get_baseline_comparison(\n",
    "    ScoreConfig(ScoreType.Rel, overfit_iterations_info=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_best_model = CatBoostClassifier(iterations=10)\n",
    "my_best_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    cat_features=cat_features,\n",
    "    verbose=False\n",
    ")\n",
    "my_best_model.save_model('catboost_model.bin')\n",
    "my_best_model.save_model('catboost_model.json', format='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_best_model.load_model('catboost_model.bin')\n",
    "print(my_best_model.get_params())\n",
    "print(my_best_model.random_seed_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoost\n",
    "fast_model = CatBoostClassifier(\n",
    "    random_seed=63,\n",
    "    iterations=150,\n",
    "    learning_rate=0.01,\n",
    "    boosting_type='Plain',\n",
    "    bootstrap_type='Bernoulli',\n",
    "    subsample=0.5,\n",
    "    one_hot_max_size=20,\n",
    "    rsm=0.5,\n",
    "    leaf_estimation_iterations=5,\n",
    "    max_ctr_complexity=1)\n",
    "\n",
    "fast_model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    verbose=False,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunned_model = CatBoostClassifier(\n",
    "    random_seed=63,\n",
    "    iterations=500,\n",
    "    learning_rate=0.03,\n",
    "    l2_leaf_reg=3,\n",
    "    bagging_temperature=1,\n",
    "    random_strength=1,\n",
    "    one_hot_max_size=2,\n",
    "    leaf_estimation_method='Newton'\n",
    ")\n",
    "tunned_model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    verbose=False,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model after parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = CatBoostClassifier(\n",
    "    random_seed=63,\n",
    "    iterations=int(tunned_model.tree_count_ * 1.2),\n",
    ")\n",
    "best_model.fit(\n",
    "    X, y,\n",
    "    cat_features=cat_features,\n",
    "    verbose=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate predictions for the contest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_pool = Pool(data=X_test, cat_features=cat_features)\n",
    "contest_predictions = b\n",
    "print('Predictoins:')\n",
    "print(contest_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "ypred = model.predict(X)\n",
    "roc_auc_score(ypred,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat1 = pd.read_csv(r\"sample_submission_eyYijxG.csv\")\n",
    "sat1['Is_Lead'] = model1.predict(test_df)\n",
    "sat1.to_csv('submisssion1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('submit.csv', 'w')\n",
    "f.write('Id,Action\\n')\n",
    "for idx in range(len(contest_predictions)):\n",
    "    line = str(test_df['id'][idx]) + ',' + str(contest_predictions[idx][1]) + '\\n'\n",
    "    f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender, Region_Code, Occupation, Channel_Code, Credit_Product, Is_Active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_gpu1\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_gpu1\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_gpu1\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_gpu1\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_gpu1\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_gpu1\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_gpu1\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_gpu1\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_gpu1\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_gpu1\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_gpu1\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\tf_gpu1\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#Label Encoding\n",
    "# above i have checked the dtype and i am now converting all the object and bool to string for further use.\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "X_train['Gender']=X_train['Gender'].astype(str)\n",
    "X_train['Region_Code']=X_train['Region_Code'].astype(str)\n",
    "X_train['Occupation']=X_train['Occupation'].astype(str)\n",
    "X_train['Channel_Code']=X_train['Channel_Code'].astype(str)\n",
    "X_train['Credit_Product']=X_train['Credit_Product'].astype(str)\n",
    "X_train['Is_Active']=X_train['Is_Active'].astype(str)\n",
    "\n",
    "\n",
    "# converting all the categories to numeric format as model does not take data in english.\n",
    "\n",
    "X_train['Gender']=LabelEncoder().fit_transform(X_train['Gender'])\n",
    "X_train['Region_Code']=LabelEncoder().fit_transform(X_train['Region_Code'])\n",
    "X_train['Occupation']=LabelEncoder().fit_transform(X_train['Occupation'])\n",
    "X_train['Channel_Code']=LabelEncoder().fit_transform(X_train['Channel_Code'])\n",
    "X_train['Credit_Product']=LabelEncoder().fit_transform(X_train['Credit_Product'])\n",
    "X_train['Is_Active']=LabelEncoder().fit_transform(X_train['Is_Active'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                 0\n",
       "Age                    0\n",
       "Region_Code            0\n",
       "Occupation             0\n",
       "Channel_Code           0\n",
       "Vintage                0\n",
       "Credit_Product         0\n",
       "Avg_Account_Balance    0\n",
       "Is_Active              0\n",
       "Is_Active              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the lightgbm model\n",
    "#!pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "clf = lgb.LGBMClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8421182365791329"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "ypred = clf.predict(X_train)\n",
    "roc_auc_score(ypred,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Channel_Code</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Credit_Product</th>\n",
       "      <th>Avg_Account_Balance</th>\n",
       "      <th>Is_Active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>29</td>\n",
       "      <td>RG254</td>\n",
       "      <td>Other</td>\n",
       "      <td>X1</td>\n",
       "      <td>25</td>\n",
       "      <td>Yes</td>\n",
       "      <td>742366</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>43</td>\n",
       "      <td>RG268</td>\n",
       "      <td>Other</td>\n",
       "      <td>X2</td>\n",
       "      <td>49</td>\n",
       "      <td>nc</td>\n",
       "      <td>925537</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>RG270</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>X1</td>\n",
       "      <td>14</td>\n",
       "      <td>No</td>\n",
       "      <td>215949</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>29</td>\n",
       "      <td>RG272</td>\n",
       "      <td>Other</td>\n",
       "      <td>X1</td>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>868070</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>RG270</td>\n",
       "      <td>Other</td>\n",
       "      <td>X1</td>\n",
       "      <td>19</td>\n",
       "      <td>No</td>\n",
       "      <td>657087</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105307</th>\n",
       "      <td>Male</td>\n",
       "      <td>52</td>\n",
       "      <td>RG268</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>X2</td>\n",
       "      <td>86</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4242558</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105308</th>\n",
       "      <td>Male</td>\n",
       "      <td>55</td>\n",
       "      <td>RG277</td>\n",
       "      <td>Other</td>\n",
       "      <td>X2</td>\n",
       "      <td>86</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1159153</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105309</th>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>RG254</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>X4</td>\n",
       "      <td>15</td>\n",
       "      <td>No</td>\n",
       "      <td>1703727</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105310</th>\n",
       "      <td>Male</td>\n",
       "      <td>53</td>\n",
       "      <td>RG254</td>\n",
       "      <td>Other</td>\n",
       "      <td>X3</td>\n",
       "      <td>93</td>\n",
       "      <td>No</td>\n",
       "      <td>737178</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105311</th>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>RG256</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>X1</td>\n",
       "      <td>21</td>\n",
       "      <td>No</td>\n",
       "      <td>591565</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105312 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Gender  Age Region_Code Occupation Channel_Code  Vintage  \\\n",
       "0         Male   29       RG254      Other           X1       25   \n",
       "1         Male   43       RG268      Other           X2       49   \n",
       "2         Male   31       RG270   Salaried           X1       14   \n",
       "3         Male   29       RG272      Other           X1       33   \n",
       "4       Female   29       RG270      Other           X1       19   \n",
       "...        ...  ...         ...        ...          ...      ...   \n",
       "105307    Male   52       RG268   Salaried           X2       86   \n",
       "105308    Male   55       RG277      Other           X2       86   \n",
       "105309    Male   35       RG254   Salaried           X4       15   \n",
       "105310    Male   53       RG254      Other           X3       93   \n",
       "105311    Male   27       RG256   Salaried           X1       21   \n",
       "\n",
       "       Credit_Product  Avg_Account_Balance Is_Active  \n",
       "0                 Yes               742366        No  \n",
       "1                  nc               925537        No  \n",
       "2                  No               215949        No  \n",
       "3                  No               868070        No  \n",
       "4                  No               657087        No  \n",
       "...               ...                  ...       ...  \n",
       "105307            Yes              4242558       Yes  \n",
       "105308            Yes              1159153        No  \n",
       "105309             No              1703727        No  \n",
       "105310             No               737178       Yes  \n",
       "105311             No               591565        No  \n",
       "\n",
       "[105312 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding\n",
    "# above i have checked the dtype and i am now converting all the object and bool to string for further use.\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "X_train['Gender']=X_train['Gender'].astype(str)\n",
    "X_train['Region_Code']=X_train['Region_Code'].astype(str)\n",
    "X_train['Occupation']=X_train['Occupation'].astype(str)\n",
    "X_train['Channel_Code']=X_train['Channel_Code'].astype(str)\n",
    "X_train['Credit_Product']=X_train['Credit_Product'].astype(str)\n",
    "X_train['Is_Active']=X_train['Is_Active'].astype(str)\n",
    "\n",
    "\n",
    "# converting all the categories to numeric format as model does not take data in english.\n",
    "\n",
    "X_train['Gender']=LabelEncoder().fit_transform(X_train['Gender'])\n",
    "X_train['Region_Code']=LabelEncoder().fit_transform(X_train['Region_Code'])\n",
    "X_train['Occupation']=LabelEncoder().fit_transform(X_train['Occupation'])\n",
    "X_train['Channel_Code']=LabelEncoder().fit_transform(X_train['Channel_Code'])\n",
    "X_train['Credit_Product']=LabelEncoder().fit_transform(X_train['Credit_Product'])\n",
    "X_train['Is_Active']=LabelEncoder().fit_transform(X_train['Is_Active'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features_ is 10 and input n_features is 9 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-cf7324327fad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msat1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"sample_submission_eyYijxG.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msat1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Is_Lead'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msat1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'submisssion2.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu1\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    906\u001b[0m         \u001b[1;34m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         result = self.predict_proba(X, raw_score, start_iteration, num_iteration,\n\u001b[1;32m--> 908\u001b[1;33m                                     pred_leaf, pred_contrib, **kwargs)\n\u001b[0m\u001b[0;32m    909\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_objective\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mraw_score\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu1\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    918\u001b[0m                       pred_leaf=False, pred_contrib=False, **kwargs):\n\u001b[0;32m    919\u001b[0m         \u001b[1;34m\"\"\"Docstring is set after definition, using a template.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_objective\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mraw_score\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m             _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu1\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    723\u001b[0m                              \u001b[1;34m\"match the input. Model n_features_ is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m                              % (self._n_features, n_features))\n\u001b[0m\u001b[0;32m    726\u001b[0m         return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n\u001b[0;32m    727\u001b[0m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features_ is 10 and input n_features is 9 "
     ]
    }
   ],
   "source": [
    "sat1 = pd.read_csv(r\"sample_submission_eyYijxG.csv\")\n",
    "sat1['Is_Lead'] = clf.predict(test_df)\n",
    "sat1.to_csv('submisssion2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit your solution [here](https://www.kaggle.com/c/amazon-employee-access-challenge/submit).\n",
    "Good luck!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "state": {
    "1057714ebc614324aa3ba2cf69408966": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "8381e9eed05f4a03905ae8a56d7ab4ea": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "f49684e8c5c44241bfe2c7f577f5cb41": {
     "views": [
      {
       "cell_index": 53
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
