{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kWnEizcXxNMA"
   },
   "outputs": [],
   "source": [
    "#mahesh.s \n",
    "#20202aie0005\n",
    "#ai branch(mtech) presidency\n",
    "#professor- Dr smitha rao\n",
    "\n",
    "#import libaries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kP1iMGmbxPrv"
   },
   "outputs": [],
   "source": [
    "#read the csv\n",
    "df= pd.read_csv(r\"/content/cleaned_tweets.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "40jyBB5fTwOn",
    "outputId": "c2a180ec-f24e-44f3-f57d-7da209128c90"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>real good moment missssssssss much</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reading manga http plurk com p mzp1e</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comeagainjen http twitpic com y2lx http www yo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lapcat need send em accountant tomorrow oddly ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>add myspace myspace com lookthunder</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  label\n",
       "0                 real good moment missssssssss much    0.0\n",
       "1               reading manga http plurk com p mzp1e    0.0\n",
       "2  comeagainjen http twitpic com y2lx http www yo...    0.0\n",
       "3  lapcat need send em accountant tomorrow oddly ...    0.0\n",
       "4                add myspace myspace com lookthunder    0.0"
      ]
     },
     "execution_count": 123,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "sHR5dZxayCcv"
   },
   "outputs": [],
   "source": [
    "#methord 1\n",
    "\n",
    "#import variable X\n",
    "import json\n",
    "with open(\"/content/X.txt\", \"r\") as fp:\n",
    "  X = json.load(fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nsIgNcXr0wkj"
   },
   "outputs": [],
   "source": [
    "#methord 2\n",
    "c = df['message'].astype('str').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2nWYTOc6AAg"
   },
   "outputs": [],
   "source": [
    "#spliting the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, df.label, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3ihXeJhRk0q"
   },
   "outputs": [],
   "source": [
    "#unknown data\n",
    "qtest = ['depressed','happy','i am sad','i am happy','i am sleepy','tears of joy','i am depressed','happy tears']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bDdmh7wdyO-m",
    "outputId": "08256b39-f0d9-49e8-83b4-8f8eaedc3603"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1# naive_bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "llvVIN-EyTds",
    "outputId": "82ca609b-71c4-4917-81f0-ca97e02f49e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9143272023233301\n",
      "                              \n",
      "roc_auc_score 0.9456418155223616\n",
      "                              \n",
      "confusion_matrix \n",
      "[[1584  174]\n",
      " [   3  305]]\n",
      "                              \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.90102   0.99811   0.94709      1587\n",
      "         1.0    0.99026   0.63674   0.77510       479\n",
      "\n",
      "    accuracy                        0.91433      2066\n",
      "   macro avg    0.94564   0.81743   0.86109      2066\n",
      "weighted avg    0.92171   0.91433   0.90721      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "1# naive_bayes model prediction\n",
    "y_pred = nb.predict(x_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(\" \"*30)\n",
    "print('roc_auc_score %s' % roc_auc_score(y_pred, y_test))\n",
    "print(\" \"*30)\n",
    "print('confusion_matrix ')\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(\" \"*30)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CFdcAgnL_u0o",
    "outputId": "de097cb8-7c4e-4b8c-94fb-51bf09d4f63d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['depressed', 'happy', 'i am sad', 'i am happy', 'i am sleepy', 'tears of joy', 'i am depressed', 'happy tears']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 130,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1#naive_bayes model unknown text prediction\n",
    "print(qtest)\n",
    "nb.predict(qtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9H7yRNyC6kaQ",
    "outputId": "5d391cb7-e3d9-4f9d-e188-c5bb5bca82a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=1, penalty='l2',\n",
       "                                    random_state=None, solver='lbfgs',\n",
       "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2#logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NB9NQaqu7Nus",
    "outputId": "d4f7676c-21d6-4c46-f4b9-d3302034f34b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.968054211035818\n",
      "                              \n",
      "roc_auc_score 0.9470683761654383\n",
      "                              \n",
      "confusion_matrix \n",
      "[[1539   18]\n",
      " [  48  461]]\n",
      "                              \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.98844   0.96975   0.97901      1587\n",
      "         1.0    0.90570   0.96242   0.93320       479\n",
      "\n",
      "    accuracy                        0.96805      2066\n",
      "   macro avg    0.94707   0.96609   0.95610      2066\n",
      "weighted avg    0.96926   0.96805   0.96839      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "2##logistic regression model prediction\n",
    "y_pred = logreg.predict(x_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(\" \"*30)\n",
    "print('roc_auc_score %s' % roc_auc_score(y_pred, y_test))\n",
    "print(\" \"*30)\n",
    "print('confusion_matrix ')\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(\" \"*30)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0HiWaeNJ7TG3",
    "outputId": "e617c6b3-dbc5-4de0-cf9f-d4baecde7831"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['depressed', 'happy', 'i am sad', 'i am happy', 'i am sleepy', 'tears of joy', 'i am depressed', 'happy tears']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 1., 1., 1., 0.])"
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2#logistic regression model unknown prediction\n",
    "print(qtest)\n",
    "logreg.predict(qtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-EdoqEPw7b7m",
    "outputId": "cfabaad1-4de5-404d-e622-72005aaf3ab0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=3, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 134,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3# KNeighborsClassifier model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knc = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf',  KNeighborsClassifier(3))\n",
    "                ])\n",
    "\n",
    "knc.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29RksCfk8pDp",
    "outputId": "63eeb0a0-faeb-4e8d-e60d-ec822eb08daa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.2894482090997096\n",
      "                              \n",
      "roc_auc_score 0.6187469459729333\n",
      "                              \n",
      "confusion_matrix \n",
      "[[ 120    1]\n",
      " [1467  478]]\n",
      "                              \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.99174   0.07561   0.14052      1587\n",
      "         1.0    0.24576   0.99791   0.39439       479\n",
      "\n",
      "    accuracy                        0.28945      2066\n",
      "   macro avg    0.61875   0.53676   0.26745      2066\n",
      "weighted avg    0.81878   0.28945   0.19938      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "3#KNeighborsClassifier model prediction\n",
    "y_pred = knc.predict(x_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(\" \"*30)\n",
    "print('roc_auc_score %s' % roc_auc_score(y_pred, y_test))\n",
    "print(\" \"*30)\n",
    "print('confusion_matrix ')\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(\" \"*30)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rxomm8MI_hQX",
    "outputId": "f35fcb76-00c6-4b03-eea1-8adc53b0a54a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['depressed', 'happy', 'i am sad', 'i am happy', 'i am sleepy', 'tears of joy', 'i am depressed', 'happy tears']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": 136,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3#KNeighborsClassifier unknown prediction\n",
    "print(qtest)\n",
    "knc.predict(qtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fXz7plV3_pxr",
    "outputId": "4c662d00-2f4a-40db-9f7b-dccb8453acd9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 LogisticRegressionCV(Cs=10, class_weight=None, cv=None,\n",
       "                                      dual=False, fit_intercept=True,\n",
       "                                      intercept_scaling=1.0, l1_ratios=None,\n",
       "                                      max_iter=100, multi_class='auto',\n",
       "                                      n_jobs=None, penalty='l2',\n",
       "                                      random_state=None, refit=True,\n",
       "                                      scoring=None, solver='lbfgs', tol=0.0001,\n",
       "                                      verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 137,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4# LogisticRegressionCV model\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "\n",
    "regcv = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegressionCV()),\n",
    "               ])\n",
    "regcv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EvDE4MklUAGt",
    "outputId": "cc5ea74b-9cba-4d6b-a258-8575b9f2da55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9888673765730881\n",
      "                              \n",
      "roc_auc_score 0.9905188327881594\n",
      "                              \n",
      "confusion_matrix \n",
      "[[1584   20]\n",
      " [   3  459]]\n",
      "                              \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.98753   0.99811   0.99279      1587\n",
      "         1.0    0.99351   0.95825   0.97556       479\n",
      "\n",
      "    accuracy                        0.98887      2066\n",
      "   macro avg    0.99052   0.97818   0.98418      2066\n",
      "weighted avg    0.98892   0.98887   0.98880      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "4#LogisticRegressionCV  model prediction\n",
    "y_pred = regcv.predict(x_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(\" \"*30)\n",
    "print('roc_auc_score %s' % roc_auc_score(y_pred, y_test))\n",
    "print(\" \"*30)\n",
    "print('confusion_matrix ')\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(\" \"*30)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eXdfzj4iUEN6",
    "outputId": "1d37c958-3851-407f-c7d0-cdda4a89f677"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['depressed', 'happy', 'i am sad', 'i am happy', 'i am sleepy', 'tears of joy', 'i am depressed', 'happy tears']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 139,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4#LogisticRegressionCV model unknown prediction\n",
    "print(qtest)\n",
    "regcv.predict(qtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WLLoPzBn3rxL",
    "outputId": "0475aaf4-aad9-446b-8d58-790ac6a1e780"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 140,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5# other random models testing\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "rand = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', RandomForestClassifier()),\n",
    "               ])\n",
    "rand.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gs3vDLqw4Ss9",
    "outputId": "96d9074e-05f8-4f7e-e973-edbaee03b3af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9607938044530494\n",
      "                              \n",
      "roc_auc_score 0.9332454092288291\n",
      "                              \n",
      "confusion_matrix \n",
      "[[1522   16]\n",
      " [  65  463]]\n",
      "                              \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.98960   0.95904   0.97408      1587\n",
      "         1.0    0.87689   0.96660   0.91956       479\n",
      "\n",
      "    accuracy                        0.96079      2066\n",
      "   macro avg    0.93325   0.96282   0.94682      2066\n",
      "weighted avg    0.96347   0.96079   0.96144      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "5#random model prediction\n",
    "y_pred = rand.predict(x_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(\" \"*30)\n",
    "print('roc_auc_score %s' % roc_auc_score(y_pred, y_test))\n",
    "print(\" \"*30)\n",
    "print('confusion_matrix ')\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(\" \"*30)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZrRKqVic4UkX",
    "outputId": "4934835d-f666-430a-a3e0-a322508ef5ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['depressed', 'happy', 'i am sad', 'i am happy', 'i am sleepy', 'tears of joy', 'i am depressed', 'happy tears']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 1., 1., 1., 0.])"
      ]
     },
     "execution_count": 142,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5#random unknown prediction\n",
    "print(qtest)\n",
    "rand.predict(qtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qe1KIxNGUPLR",
    "outputId": "75de67f7-1e00-4b91-98e9-faa3c84851f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter tweet (if multiple tweets sep=','): jnjjkn\n",
      "the tweet is :  ['jnjjkn']\n",
      "**************************************************\n",
      " 0 is not depressed and 1 is depressed : \n",
      "**************************************************\n",
      "['jnjjkn'] naive_bayes model\n",
      "[0.]\n",
      "====================\n",
      "['jnjjkn'] logistic regression model\n",
      "[1.]\n",
      "====================\n",
      "['jnjjkn'] KNeighborsClassifier model\n",
      "[1.]\n",
      "====================\n",
      "['jnjjkn'] LogisticRegressionCV model\n",
      "[0.]\n",
      "====================\n",
      "['jnjjkn'] random model\n",
      "[1.]\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# naive_bayes model =nb\n",
    "#logistic regression model =logreg\n",
    "#KNeighborsClassifier model model = knc\n",
    "#LogisticRegressionCV model = regcv\n",
    "#random = rand\n",
    "models=[nb,logreg,knc,regcv,rand]\n",
    "\n",
    "\n",
    "input_tweets = [str(x) for x in input(\"Enter tweet (if multiple tweets sep=','): \").split(\",\"and'.',-1)]\n",
    "\n",
    "print(\"the tweet is : \", input_tweets) \n",
    "print(\"*\"*50) \n",
    "print(\" 0 is not depressed and 1 is depressed : \")\n",
    "print(\"*\"*50)  \n",
    "\n",
    "\n",
    "# prediction\n",
    "print(input_tweets,\"naive_bayes model\")\n",
    "print(nb.predict(input_tweets))\n",
    "print(\"=\"*20) \n",
    "\n",
    "print(input_tweets,\"logistic regression model\")\n",
    "print(logreg.predict(input_tweets))\n",
    "print(\"=\"*20) \n",
    "\n",
    "print(input_tweets,\"KNeighborsClassifier model\")\n",
    "print(knc.predict(input_tweets))\n",
    "print(\"=\"*20) \n",
    "\n",
    "print(input_tweets,\"LogisticRegressionCV model\")\n",
    "print(regcv.predict(input_tweets))\n",
    "print(\"=\"*20) \n",
    "\n",
    "print(input_tweets,\"random model\")\n",
    "print(rand.predict(input_tweets))\n",
    "print(\"*\"*50) \n",
    "\n",
    "#real sucide notes to test:\n",
    "\n",
    "#I am going to die in office…Please leave immediately if you have a weak stomach or mind since I don’t want to cause physical or mental distress.\n",
    "#Things just seemed to go too wrong too many times.\n",
    "#I am haunted by the vivid memories of killings and corpses and anger and pain of starving or wounded children, of trigger-happy madmen, often police, of killer executioners\n",
    "#I myself and my wife – in order to escape the disgrace of deposition or capitulation – choose death\n",
    "#I don't want to hurt you or anybody so please forget about me. Just try. Find yourself a better friend\n",
    "#When all usefulness is over, when one is assured of an unavoidable and imminent death, it is the simplest of human rights to choose a quick and easy death in place of a slow and horrible one\n",
    "#Death is before me today As a man longs to see his houseWhen he has spent years in captivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_ZtglhgrdPU",
    "outputId": "d2932621-025c-4f25-a94c-41204db1574f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 144,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(logreg,'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NaaykiFatVVj",
    "outputId": "12c4da5a-d3cf-4627-e99d-9a6c378dec1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 1., 1., 1., 0.])"
      ]
     },
     "execution_count": 146,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = joblib.load('/content/model.pkl')\n",
    "pipe.predict(qtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-D-qjmG2qthD"
   },
   "source": [
    "#conclusion\n",
    "i choose logistic regression as my best model as it is generalized well and its roc_auc_score is 0.94"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "project 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
